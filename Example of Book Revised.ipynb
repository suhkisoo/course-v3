{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNUyaRdUiuGeJBOM5jrijl6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suhkisoo/course-v3/blob/master/Example%20of%20Book%20Revised.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0oi5nujci0T"
      },
      "source": [
        "# Download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zwo857ncfYE"
      },
      "source": [
        "!pip install tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYuqr8uocfCQ"
      },
      "source": [
        "!pip install keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOmpBUDRbC6S"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2lVRPCXahtP"
      },
      "source": [
        "# train a generative adversarial network on a one-dimensional function\n",
        "from numpy import hstack\n",
        "from numpy import zeros\n",
        "from numpy import ones\n",
        "from numpy.random import rand\n",
        "from numpy.random import randn\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from matplotlib import pyplot"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tD4tQj9KbIVb"
      },
      "source": [
        "# Define"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_a1LDh6ah8X"
      },
      "source": [
        "# define the standalone discriminator model\n",
        "def define_discriminator(n_inputs=2):\n",
        "    # class Sequential(Model) = Linear stack of layers\n",
        "    # The `Model` class adds training & evaluation routines to a `Network`.\n",
        "    # class Model(Network): add(self, layer): \tAdds a layer instance on top of the layer stack.\n",
        "\n",
        "    model = Sequential()  # model is an object of class Sequential\n",
        "    model.add(Dense(25, activation='relu', kernel_initializer='he_uniform', input_dim=n_inputs))\n",
        "    # n_inputs = 2; n_output=25\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    # n_input = 25 = n_output of the previous layer; n_output =1 ( its value o or 1)\n",
        "    # compile model\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    # model.loss = loss =\"binary_crossentropy\"\n",
        "    return model  # model is a reference  to the current instance of the class"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRWZti8GaiDd"
      },
      "source": [
        "# define the standalone generator model\n",
        "def define_generator(latent_dim, n_outputs=2):  # latent_dim =5\n",
        "    model = Sequential()\n",
        "    model.add(Dense(15, activation='relu', kernel_initializer='he_uniform',\n",
        "                    input_dim=latent_dim))  # n_input=5 = latent_dim; n_output=15\n",
        "    model.add(Dense(n_outputs, activation='linear'))  # n_input = 15 = n_output of the previous layer; n_output = 2\n",
        "    return model"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjWtTm7kaiGW"
      },
      "source": [
        "# define the combined generator and discriminator model, for updating the generator\n",
        "def define_gan(generator, discriminator):\n",
        "    # make weights in the discriminator not trainable\n",
        "    discriminator.trainable = False  # discriminator is set as not trainable when it is part of the composite model\n",
        "    # But it is trainable when it is used alone\n",
        "    # connect them\n",
        "    model = Sequential()\n",
        "    # add generator\n",
        "    model.add(generator)\n",
        "    # add the discriminator\n",
        "    model.add(discriminator)\n",
        "    # compile model\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "    # model.loss = loss =\"binary_crossentropy\"\n",
        "    return model"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQ6WeZGraiJb"
      },
      "source": [
        "#  Making the discriminator not trainable is a clever trick in the Keras API. The trainable\n",
        "#  property impacts the model when it is compiled. The discriminator model was compiled with\n",
        "#  trainable layers, therefore the model weights in those layers will be updated when the standalone\n",
        "#  model is updated via calls to train on batch()."
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fhZcsQdaiM9"
      },
      "source": [
        "# generate n real samples with class labels\n",
        "def generate_real_samples(n):\n",
        "    # generate inputs in [-0.5, 0.5]\n",
        "    X1 = rand(n) - 0.5\n",
        "    # generate outputs X^2\n",
        "    X2 = X1 * X1\n",
        "    # stack arrays\n",
        "    X1 = X1.reshape(n, 1)\n",
        "    X2 = X2.reshape(n, 1)\n",
        "    X = hstack((X1, X2))  # X =  hstack( [1,2], [3,4] ) ==>[ [1,3],[2,4] ] : 128 points\n",
        "    # generate class labels\n",
        "    y = ones((n, 1))  # y = 128 labels\n",
        "    return X, y  # # A pair of 128 real samples and their 128 labels"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOxu8xiDayBE"
      },
      "source": [
        "# generate points in latent space as input for the generator\n",
        "def generate_latent_points(latent_dim, n):\n",
        "    # generate points in the latent space\n",
        "    x_input = randn(latent_dim * n)  # [01, 02, 0.9,...., 0,1]\n",
        "    # reshape into a batch of inputs for the network\n",
        "    x_input = x_input.reshape(n, latent_dim)  # 128 * 5 matrix\n",
        "    return x_input"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdcFBdJTayIq"
      },
      "source": [
        "# use the generator to generate n fake examples, with class labels\n",
        "def generate_fake_samples(generator, latent_dim, n):\n",
        "    # generate points in latent space\n",
        "    x_input = generate_latent_points(latent_dim, n)  # 128 x 5: 128 samples of 5 random numbers\n",
        "    # predict outputs\n",
        "    X = generator.predict(x_input)  # X = 128 generator outputs for 128 samples of 5 numbers\n",
        "    # create class labels\n",
        "    y = zeros((n, 1))  # y = 128  labels\n",
        "    return X, y  # A pair of 128 fake samples and their 128 labels"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "725wIROIa2lk"
      },
      "source": [
        "# evaluate the discriminator and plot real and fake points\n",
        "def summarize_performance(epoch, generator, discriminator, latent_dim, n=100):\n",
        "    # prepare real samples\n",
        "    x_real, y_real = generate_real_samples(n)  # (x_real, y_real):  A pair of 128 real samples and their 128 labels\n",
        "    # evaluate discriminator on real examples\n",
        "    _, acc_real = discriminator.evaluate(x_real, y_real,\n",
        "                                         verbose=0)  # acc_real = THe accuray of the discriminator net that tells \"real\" for real samples\n",
        "    # prepare fake examples\n",
        "    x_fake, y_fake = generate_fake_samples(generator, latent_dim,\n",
        "                                           n)  # (x_fake, y_fake):  # A pair of 128 fake samples and their 128 labels\n",
        "    # evaluate discriminator on fake examples\n",
        "    _, acc_fake = discriminator.evaluate(x_fake, y_fake,\n",
        "                                         verbose=0)  # acc_fake = The accuray of the discriminator net that tells \"fake\" for fake samples\n",
        "    # summarize discriminator performance\n",
        "    print(epoch, acc_real, acc_fake)  # acc_real = accuray of the discriminator net that says \"real\" for real samples\n",
        "    # scatter plot real and fake data points\n",
        "    pyplot.scatter(x_real[:, 0], x_real[:, 1], color='red')\n",
        "    pyplot.scatter(x_fake[:, 0], x_fake[:, 1], color='blue')\n",
        "    # save plot to file\n",
        "    filename = 'generated_plot_e%03d.png' % (epoch + 1)\n",
        "    pyplot.savefig(filename)\n",
        "    pyplot.close()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shjRYbYFa2rp"
      },
      "source": [
        "# train the generator and discriminator\n",
        "def train(g_model, d_model, gan_model, latent_dim, n_epochs=10000, n_batch=128, n_eval=2000):\n",
        "    # determine half the size of one batch, for updating the discriminator\n",
        "    half_batch = int(n_batch / 2)\n",
        "    # manually enumerate epochs\n",
        "    for i in range(n_epochs):\n",
        "        # prepare real samples\n",
        "        x_real, y_real = generate_real_samples(half_batch)\n",
        "        # prepare fake examples\n",
        "        x_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
        "        # update discriminator\n",
        "        # \"Runs a single gradient update on a single batch of data\":\n",
        "        d_model.train_on_batch(x_real, y_real)  # train the discriminator using real samples\n",
        "        d_model.train_on_batch(x_fake,\n",
        "                               y_fake)  # train the discriminator using the fake samples generated by the current generator net.\n",
        "        # prepare points in latent space as input for the generator\n",
        "        x_gan = generate_latent_points(latent_dim,\n",
        "                                       n_batch)  # x_gan = 128 x 5 matrix \\\\> This means 128 samples of 5 random numbers\n",
        "        # create inverted labels for the fake samples\n",
        "        y_gan = ones((n_batch, 1))  # 128 1's\n",
        "        # update the generator via the discriminator's error\n",
        "        gan_model.train_on_batch(x_gan,\n",
        "                                 y_gan)  # train the generator (g_model)  with the discriminator frozen:  x_gan=input, y_gan=target=label\n",
        "        # evaluate the model every n_eval epochs\n",
        "        if (i + 1) % n_eval == 0:\n",
        "            summarize_performance(i, g_model, d_model, latent_dim)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPKqrK8sbPOT"
      },
      "source": [
        "# Main Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2Ob3t6na8VB",
        "outputId": "14dfaf50-eed8-4bac-be30-e700a81a33df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# size of the latent space\n",
        "latent_dim = 5\n",
        "# create the discriminator\n",
        "discriminator = define_discriminator()\n",
        "#  discriminator is a reference  to the instance of the Sequential class\n",
        "#  discriminator defines the loss function and the optimization method\n",
        "\n",
        "# create the generator\n",
        "generator = define_generator(latent_dim)  # generator does not define  the loss function and the optimization method\n",
        "# create the gan\n",
        "gan_model = define_gan(generator, discriminator)\n",
        "# train model\n",
        "train(generator, discriminator, gan_model, latent_dim)\n",
        "# train the discriminator on real samples and the fake samples generated by the current generator net\n",
        "# Then, train the generator with the discriminator set frozen (not trainable)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1999 0.6899999976158142 0.550000011920929\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}